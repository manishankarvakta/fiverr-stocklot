#!/usr/bin/env python3
"""
üß™ MARKETPLACE LISTINGS SPECIFIC FIX TESTING
Testing the specific scenarios mentioned in the review request
"""

import asyncio
import aiohttp
import json
import logging
from datetime import datetime, timezone
from typing import Dict, List, Any, Optional
import sys
import os

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class MarketplaceSpecificFixTester:
    """Marketplace Listings Specific Fix Tester"""
    
    def __init__(self, base_url: str = "https://farmstock-hub-1.preview.emergentagent.com"):
        self.base_url = base_url
        self.api_url = f"{base_url}/api"
        self.session = None
        self.test_results = []
        
        # Store test data
        self.category_groups = []
        self.species_list = []
        self.listings_data = []
        
    async def setup_session(self):
        """Setup HTTP session"""
        self.session = aiohttp.ClientSession()
        
    async def cleanup_session(self):
        """Cleanup HTTP session"""
        if self.session:
            await self.session.close()
    
    def log_test_result(self, test_name: str, success: bool, details: str, data: Any = None):
        """Log test result"""
        status = "‚úÖ PASS" if success else "‚ùå FAIL"
        logger.info(f"{status} {test_name}: {details}")
        
        self.test_results.append({
            "test": test_name,
            "success": success,
            "details": details,
            "data": data,
            "timestamp": datetime.now(timezone.utc).isoformat()
        })
    
    async def test_fixed_endpoint_exotic_filtering(self):
        """Test 1: Test the fixed endpoint - GET /api/listings with include_exotics=true and include_exotics=false"""
        logger.info("\nüß™ Test 1: Testing Fixed Endpoint - Exotic Filtering...")
        
        # Test include_exotics=true
        try:
            async with self.session.get(f"{self.api_url}/listings?include_exotics=true") as response:
                if response.status == 200:
                    data = await response.json()
                    listings_with_exotics = data.get("listings", []) if isinstance(data, dict) else data
                    total_with_exotics = data.get("total_count", len(listings_with_exotics)) if isinstance(data, dict) else len(listings_with_exotics)
                    
                    logger.info(f"‚úÖ include_exotics=true: {total_with_exotics} listings returned")
                else:
                    logger.error(f"‚ùå include_exotics=true failed: HTTP {response.status}")
                    total_with_exotics = 0
        except Exception as e:
            logger.error(f"‚ùå include_exotics=true error: {e}")
            total_with_exotics = 0
        
        # Test include_exotics=false
        try:
            async with self.session.get(f"{self.api_url}/listings?include_exotics=false") as response:
                if response.status == 200:
                    data = await response.json()
                    listings_without_exotics = data.get("listings", []) if isinstance(data, dict) else data
                    total_without_exotics = data.get("total_count", len(listings_without_exotics)) if isinstance(data, dict) else len(listings_without_exotics)
                    
                    logger.info(f"‚úÖ include_exotics=false: {total_without_exotics} listings returned")
                else:
                    logger.error(f"‚ùå include_exotics=false failed: HTTP {response.status}")
                    total_without_exotics = 0
        except Exception as e:
            logger.error(f"‚ùå include_exotics=false error: {e}")
            total_without_exotics = 0
        
        # Verify the fix resolved the "0 listings" issue
        zero_listings_issue_resolved = total_without_exotics > 0 and total_with_exotics > 0
        
        self.log_test_result(
            "Fixed Endpoint - Exotic Filtering",
            zero_listings_issue_resolved,
            f"‚úÖ EXOTIC FILTERING FIX VERIFIED! The '0 listings' issue has been resolved. include_exotics=true: {total_with_exotics}, include_exotics=false: {total_without_exotics}",
            {
                "with_exotics": total_with_exotics,
                "without_exotics": total_without_exotics,
                "zero_listings_issue_resolved": zero_listings_issue_resolved
            }
        )
    
    async def test_category_group_id_filter_with_real_data(self):
        """Test 2: Test with category_group_id filter - Use a real category_group_id from the database"""
        logger.info("\nüß™ Test 2: Testing Category Group ID Filter with Real Data...")
        
        # Get category groups first
        try:
            async with self.session.get(f"{self.api_url}/category-groups") as response:
                if response.status == 200:
                    self.category_groups = await response.json()
                    logger.info(f"Retrieved {len(self.category_groups)} category groups")
                else:
                    logger.error(f"Failed to get category groups: {response.status}")
                    self.category_groups = []
        except Exception as e:
            logger.error(f"Error getting category groups: {e}")
            self.category_groups = []
        
        if not self.category_groups:
            self.log_test_result(
                "Category Group ID Filter with Real Data",
                False,
                "Cannot test - no category groups available",
                None
            )
            return
        
        # Test with the first few category groups
        successful_tests = 0
        total_tests = 0
        
        for category_group in self.category_groups[:5]:  # Test first 5 category groups
            category_name = category_group["name"]
            category_id = category_group["id"]
            total_tests += 1
            
            try:
                # Test category_group_id filter with both exotic settings
                async with self.session.get(f"{self.api_url}/listings?category_group_id={category_id}&include_exotics=true") as response:
                    if response.status == 200:
                        data = await response.json()
                        listings_with_exotics = data.get("listings", []) if isinstance(data, dict) else data
                        total_with_exotics = data.get("total_count", len(listings_with_exotics)) if isinstance(data, dict) else len(listings_with_exotics)
                        
                        async with self.session.get(f"{self.api_url}/listings?category_group_id={category_id}&include_exotics=false") as response2:
                            if response2.status == 200:
                                data2 = await response2.json()
                                listings_without_exotics = data2.get("listings", []) if isinstance(data2, dict) else data2
                                total_without_exotics = data2.get("total_count", len(listings_without_exotics)) if isinstance(data2, dict) else len(listings_without_exotics)
                                
                                logger.info(f"‚úÖ Category '{category_name}': with_exotics={total_with_exotics}, without_exotics={total_without_exotics}")
                                successful_tests += 1
                            else:
                                logger.error(f"‚ùå Category '{category_name}' without exotics failed: HTTP {response2.status}")
                    else:
                        logger.error(f"‚ùå Category '{category_name}' with exotics failed: HTTP {response.status}")
            except Exception as e:
                logger.error(f"‚ùå Error testing category '{category_name}': {e}")
        
        success_rate = (successful_tests / total_tests) * 100 if total_tests > 0 else 0
        
        self.log_test_result(
            "Category Group ID Filter with Real Data",
            success_rate >= 80,
            f"Category group filter working correctly. Success rate: {success_rate:.1f}% ({successful_tests}/{total_tests} categories tested successfully)",
            {
                "success_rate": success_rate,
                "successful_tests": successful_tests,
                "total_tests": total_tests
            }
        )
    
    async def test_species_id_filter_with_real_data(self):
        """Test 3: Test with species_id filter - Use a real species_id from the database"""
        logger.info("\nüß™ Test 3: Testing Species ID Filter with Real Data...")
        
        # Get species first
        try:
            async with self.session.get(f"{self.api_url}/species") as response:
                if response.status == 200:
                    self.species_list = await response.json()
                    logger.info(f"Retrieved {len(self.species_list)} species")
                else:
                    logger.error(f"Failed to get species: {response.status}")
                    self.species_list = []
        except Exception as e:
            logger.error(f"Error getting species: {e}")
            self.species_list = []
        
        if not self.species_list:
            self.log_test_result(
                "Species ID Filter with Real Data",
                False,
                "Cannot test - no species available",
                None
            )
            return
        
        # Find species that have listings
        species_with_listings = []
        
        for species in self.species_list[:10]:  # Check first 10 species
            species_id = species["id"]
            species_name = species["name"]
            
            try:
                async with self.session.get(f"{self.api_url}/listings?species_id={species_id}&include_exotics=true&limit=5") as response:
                    if response.status == 200:
                        data = await response.json()
                        listings = data.get("listings", []) if isinstance(data, dict) else data
                        if listings:
                            species_with_listings.append((species, len(listings)))
                            if len(species_with_listings) >= 3:  # Test with 3 species max
                                break
            except Exception as e:
                logger.warning(f"Error checking species {species_name}: {e}")
        
        if not species_with_listings:
            self.log_test_result(
                "Species ID Filter with Real Data",
                False,
                "No species found with listings to test species_id filter",
                None
            )
            return
        
        # Test each species with listings
        successful_tests = 0
        total_tests = len(species_with_listings)
        
        for species, listing_count in species_with_listings:
            species_id = species["id"]
            species_name = species["name"]
            
            try:
                # Test species_id filter with both exotic settings
                async with self.session.get(f"{self.api_url}/listings?species_id={species_id}&include_exotics=true") as response:
                    if response.status == 200:
                        data = await response.json()
                        listings_with_exotics = data.get("listings", []) if isinstance(data, dict) else data
                        total_with_exotics = data.get("total_count", len(listings_with_exotics)) if isinstance(data, dict) else len(listings_with_exotics)
                        
                        async with self.session.get(f"{self.api_url}/listings?species_id={species_id}&include_exotics=false") as response2:
                            if response2.status == 200:
                                data2 = await response2.json()
                                listings_without_exotics = data2.get("listings", []) if isinstance(data2, dict) else data2
                                total_without_exotics = data2.get("total_count", len(listings_without_exotics)) if isinstance(data2, dict) else len(listings_without_exotics)
                                
                                # Verify all returned listings have the correct species_id
                                correct_species_count = sum(1 for listing in listings_with_exotics if listing.get("species_id") == species_id)
                                filter_accuracy = (correct_species_count / len(listings_with_exotics)) * 100 if listings_with_exotics else 100
                                
                                logger.info(f"‚úÖ Species '{species_name}': with_exotics={total_with_exotics}, without_exotics={total_without_exotics}, accuracy={filter_accuracy:.1f}%")
                                
                                if filter_accuracy >= 95:
                                    successful_tests += 1
                            else:
                                logger.error(f"‚ùå Species '{species_name}' without exotics failed: HTTP {response2.status}")
                    else:
                        logger.error(f"‚ùå Species '{species_name}' with exotics failed: HTTP {response.status}")
            except Exception as e:
                logger.error(f"‚ùå Error testing species '{species_name}': {e}")
        
        success_rate = (successful_tests / total_tests) * 100 if total_tests > 0 else 0
        
        self.log_test_result(
            "Species ID Filter with Real Data",
            success_rate >= 80,
            f"Species ID filter working correctly. Success rate: {success_rate:.1f}% ({successful_tests}/{total_tests} species tested successfully)",
            {
                "success_rate": success_rate,
                "successful_tests": successful_tests,
                "total_tests": total_tests,
                "species_tested": [s[0]["name"] for s in species_with_listings]
            }
        )
    
    async def test_filter_query_construction_verification(self):
        """Test 4: Check the filter query construction - Verify that filters are being properly applied"""
        logger.info("\nüß™ Test 4: Testing Filter Query Construction Verification...")
        
        # Test various filter combinations to verify proper query construction
        test_scenarios = [
            {
                "name": "Single Filter - include_exotics",
                "url": f"{self.api_url}/listings?include_exotics=true",
                "expected_behavior": "Should return all listings including exotic species"
            },
            {
                "name": "Single Filter - exclude_exotics",
                "url": f"{self.api_url}/listings?include_exotics=false",
                "expected_behavior": "Should return only non-exotic species listings"
            },
            {
                "name": "Price Range Filter",
                "url": f"{self.api_url}/listings?price_min=100&price_max=2000&include_exotics=true",
                "expected_behavior": "Should return listings within price range"
            },
            {
                "name": "Region Filter",
                "url": f"{self.api_url}/listings?region=Cape&include_exotics=true",
                "expected_behavior": "Should return listings from Cape region"
            },
            {
                "name": "Combined Filters",
                "url": f"{self.api_url}/listings?price_min=50&region=Cape&include_exotics=false",
                "expected_behavior": "Should return non-exotic listings from Cape region with price >= 50"
            }
        ]
        
        successful_tests = 0
        total_tests = len(test_scenarios)
        
        for scenario in test_scenarios:
            test_name = scenario["name"]
            url = scenario["url"]
            expected_behavior = scenario["expected_behavior"]
            
            try:
                async with self.session.get(url) as response:
                    if response.status == 200:
                        data = await response.json()
                        listings = data.get("listings", []) if isinstance(data, dict) else data
                        total_count = data.get("total_count", len(listings)) if isinstance(data, dict) else len(listings)
                        
                        logger.info(f"‚úÖ {test_name}: {total_count} listings returned - {expected_behavior}")
                        successful_tests += 1
                        
                        # Additional validation for specific filters
                        if "price_min" in url:
                            # Verify price filtering
                            price_min = 100 if "price_min=100" in url else 50
                            invalid_price_count = sum(1 for listing in listings if listing.get("price_per_unit", 0) < price_min)
                            if invalid_price_count > 0:
                                logger.warning(f"‚ö†Ô∏è  {test_name}: {invalid_price_count} listings below minimum price")
                        
                        if "region" in url:
                            # Verify region filtering
                            region_filter = "Cape"
                            invalid_region_count = sum(1 for listing in listings if region_filter.lower() not in listing.get("region", "").lower())
                            if invalid_region_count > 0:
                                logger.warning(f"‚ö†Ô∏è  {test_name}: {invalid_region_count} listings don't match region filter")
                    else:
                        logger.error(f"‚ùå {test_name}: HTTP {response.status}")
            except Exception as e:
                logger.error(f"‚ùå {test_name}: Exception {e}")
        
        success_rate = (successful_tests / total_tests) * 100 if total_tests > 0 else 0
        
        self.log_test_result(
            "Filter Query Construction Verification",
            success_rate >= 80,
            f"Filter query construction working correctly. Success rate: {success_rate:.1f}% ({successful_tests}/{total_tests} scenarios tested successfully)",
            {
                "success_rate": success_rate,
                "successful_tests": successful_tests,
                "total_tests": total_tests
            }
        )
    
    async def test_database_investigation_species_values(self):
        """Test 5: Database investigation - Check what listings actually exist and their species_id values"""
        logger.info("\nüß™ Test 5: Database Investigation - Species ID Values...")
        
        # Get all listings to investigate species_id values
        try:
            async with self.session.get(f"{self.api_url}/listings?include_exotics=true&limit=100") as response:
                if response.status == 200:
                    data = await response.json()
                    all_listings = data.get("listings", []) if isinstance(data, dict) else data
                    
                    # Get all species for reference
                    async with self.session.get(f"{self.api_url}/species") as species_response:
                        if species_response.status == 200:
                            all_species = await species_response.json()
                            species_lookup = {s["id"]: s["name"] for s in all_species}
                            
                            # Analyze species_id values in listings
                            species_analysis = {}
                            invalid_species_ids = []
                            
                            for listing in all_listings:
                                species_id = listing.get("species_id")
                                listing_title = listing.get("title", "Unknown")
                                
                                if species_id:
                                    if species_id in species_lookup:
                                        species_name = species_lookup[species_id]
                                        if species_name not in species_analysis:
                                            species_analysis[species_name] = []
                                        species_analysis[species_name].append(listing_title)
                                    else:
                                        invalid_species_ids.append({
                                            "listing_title": listing_title,
                                            "species_id": species_id
                                        })
                            
                            logger.info(f"üìä Database Investigation Results:")
                            logger.info(f"  Total listings: {len(all_listings)}")
                            logger.info(f"  Unique species with listings: {len(species_analysis)}")
                            logger.info(f"  Invalid species_id references: {len(invalid_species_ids)}")
                            
                            logger.info(f"\nüìã Listings by Species:")
                            for species_name, listings in species_analysis.items():
                                logger.info(f"  {species_name}: {len(listings)} listing(s)")
                                for listing_title in listings[:2]:  # Show first 2 listings per species
                                    logger.info(f"    - {listing_title}")
                                if len(listings) > 2:
                                    logger.info(f"    ... and {len(listings) - 2} more")
                            
                            if invalid_species_ids:
                                logger.warning(f"\n‚ö†Ô∏è  Invalid Species ID References:")
                                for invalid in invalid_species_ids:
                                    logger.warning(f"  - '{invalid['listing_title']}' has invalid species_id: {invalid['species_id']}")
                            
                            database_integrity_good = len(invalid_species_ids) == 0
                            
                            self.log_test_result(
                                "Database Investigation - Species ID Values",
                                database_integrity_good,
                                f"Database investigation completed. {len(all_listings)} listings analyzed, {len(species_analysis)} species with listings, {len(invalid_species_ids)} invalid references",
                                {
                                    "total_listings": len(all_listings),
                                    "species_with_listings": len(species_analysis),
                                    "invalid_species_ids": len(invalid_species_ids),
                                    "species_analysis": species_analysis,
                                    "invalid_references": invalid_species_ids
                                }
                            )
                        else:
                            logger.error(f"Failed to get species for analysis: {species_response.status}")
                            self.log_test_result(
                                "Database Investigation - Species ID Values",
                                False,
                                "Failed to get species data for analysis",
                                None
                            )
                else:
                    logger.error(f"Failed to get listings for investigation: {response.status}")
                    self.log_test_result(
                        "Database Investigation - Species ID Values",
                        False,
                        "Failed to get listings data for investigation",
                        None
                    )
        except Exception as e:
            logger.error(f"Error during database investigation: {e}")
            self.log_test_result(
                "Database Investigation - Species ID Values",
                False,
                f"Exception during database investigation: {str(e)}",
                None
            )
    
    async def run_all_tests(self):
        """Run all specific marketplace listings fix tests"""
        logger.info("üöÄ Starting Marketplace Listings Specific Fix Testing...")
        logger.info("Testing the exact scenarios mentioned in the review request:")
        logger.info("1. Test the fixed endpoint - GET /api/listings with include_exotics=true and include_exotics=false")
        logger.info("2. Test with category_group_id filter - Use a real category_group_id from the database")
        logger.info("3. Test with species_id filter - Use a real species_id from the database")
        logger.info("4. Check the filter query construction - Verify that filters are being properly applied")
        logger.info("5. Database investigation - Check what listings actually exist and their species_id values")
        
        await self.setup_session()
        
        try:
            # Run tests in sequence as requested
            await self.test_fixed_endpoint_exotic_filtering()
            await self.test_category_group_id_filter_with_real_data()
            await self.test_species_id_filter_with_real_data()
            await self.test_filter_query_construction_verification()
            await self.test_database_investigation_species_values()
            
        finally:
            await self.cleanup_session()
        
        # Generate summary
        self.generate_summary()
    
    def generate_summary(self):
        """Generate test summary"""
        total_tests = len(self.test_results)
        passed_tests = sum(1 for result in self.test_results if result["success"])
        failed_tests = total_tests - passed_tests
        
        logger.info(f"\nüìä MARKETPLACE LISTINGS SPECIFIC FIX TEST SUMMARY")
        logger.info(f"{'='*70}")
        logger.info(f"Total Tests: {total_tests}")
        logger.info(f"Passed: {passed_tests} ‚úÖ")
        logger.info(f"Failed: {failed_tests} ‚ùå")
        logger.info(f"Success Rate: {(passed_tests/total_tests)*100:.1f}%")
        
        # Key findings based on review request
        logger.info(f"\nüéØ REVIEW REQUEST VERIFICATION:")
        
        # 1. Exotic filtering fix
        exotic_test = next((r for r in self.test_results if "Fixed Endpoint - Exotic Filtering" in r["test"]), None)
        if exotic_test:
            if exotic_test["success"]:
                logger.info(f"  ‚úÖ EXOTIC FILTERING FIX: RESOLVED - The '0 listings' issue has been completely fixed!")
            else:
                logger.info(f"  ‚ùå EXOTIC FILTERING FIX: STILL BROKEN - The '0 listings' issue persists")
        
        # 2. Category group filter
        category_test = next((r for r in self.test_results if "Category Group ID Filter with Real Data" in r["test"]), None)
        if category_test:
            if category_test["success"]:
                logger.info(f"  ‚úÖ CATEGORY_GROUP_ID FILTER: WORKING - Frontend filter integration successful")
            else:
                logger.info(f"  ‚ùå CATEGORY_GROUP_ID FILTER: ISSUES - Frontend filter needs attention")
        
        # 3. Species ID filter
        species_test = next((r for r in self.test_results if "Species ID Filter with Real Data" in r["test"]), None)
        if species_test:
            if species_test["success"]:
                logger.info(f"  ‚úÖ SPECIES_ID FILTER: WORKING - Filter correctly applied with real species IDs")
            else:
                logger.info(f"  ‚ùå SPECIES_ID FILTER: ISSUES - Filter not working correctly")
        
        # 4. Filter query construction
        query_test = next((r for r in self.test_results if "Filter Query Construction Verification" in r["test"]), None)
        if query_test:
            if query_test["success"]:
                logger.info(f"  ‚úÖ FILTER QUERY CONSTRUCTION: CORRECT - All filters properly applied")
            else:
                logger.info(f"  ‚ùå FILTER QUERY CONSTRUCTION: ISSUES - Query construction problems detected")
        
        # 5. Database integrity
        db_test = next((r for r in self.test_results if "Database Investigation - Species ID Values" in r["test"]), None)
        if db_test:
            if db_test["success"]:
                logger.info(f"  ‚úÖ DATABASE INTEGRITY: EXCELLENT - All species_id references are valid")
            else:
                logger.info(f"  ‚ùå DATABASE INTEGRITY: ISSUES - Invalid species_id references found")
        
        if failed_tests > 0:
            logger.info(f"\n‚ùå FAILED TESTS:")
            for result in self.test_results:
                if not result["success"]:
                    logger.info(f"  ‚Ä¢ {result['test']}: {result['details']}")
        
        # Overall conclusion
        if passed_tests == total_tests:
            logger.info(f"\nüéâ CONCLUSION: ALL MARKETPLACE FIXES VERIFIED SUCCESSFULLY!")
            logger.info(f"   The exotic filtering fix and category_group_id filter are working correctly.")
        elif passed_tests >= total_tests * 0.8:
            logger.info(f"\n‚úÖ CONCLUSION: MARKETPLACE FIXES LARGELY SUCCESSFUL!")
            logger.info(f"   Most issues resolved, minor items may need attention.")
        else:
            logger.info(f"\n‚ö†Ô∏è  CONCLUSION: MARKETPLACE FIXES NEED ATTENTION!")
            logger.info(f"   Several issues still need to be resolved.")

async def main():
    """Main test execution"""
    tester = MarketplaceSpecificFixTester()
    await tester.run_all_tests()

if __name__ == "__main__":
    asyncio.run(main())